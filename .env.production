# =============================================================================
# Engram Production Configuration
# =============================================================================

# LLM Configuration (remote OpenAI-compatible endpoint)
LLM_BASE_URL=http://your-host:8888/v1
LLM_MODEL=kimi-k2
LLM_API_KEY=your-api-key

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=engram2024

# Embeddings (local HuggingFace model - Russian optimized)
EMBEDDING_MODEL=ai-sage/Giga-Embeddings-instruct
EMBEDDING_DIMENSIONS=1024
EMBEDDING_BATCH_SIZE=128
EMBEDDING_MULTI_GPU=true
EMBEDDING_GPU_COUNT=0

# Parallelism (optimized for high-core servers with multiple GPUs)
INGESTION_MAX_CONCURRENT=32
LLM_MAX_CONCURRENT=32

# Spreading Activation Parameters
ACTIVATION_DECAY=0.85
ACTIVATION_THRESHOLD=0.3
ACTIVATION_MAX_HOPS=3
ACTIVATION_RESCALE=0.4

# Consolidation Parameters
CONSOLIDATION_MIN_REPETITIONS=3
CONSOLIDATION_MIN_SUCCESS_RATE=0.85
CONSOLIDATION_MIN_IMPORTANCE=7.0
REFLECTION_IMPORTANCE_THRESHOLD=150.0

# Retrieval Parameters
RETRIEVAL_TOP_K=10
RETRIEVAL_BM25_K=20
RETRIEVAL_VECTOR_K=20

# BM25 Parameters
BM25_LEMMATIZE=false

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false
